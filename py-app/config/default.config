[cltl.audio]
sampling_rate: 16000
channels: 1
sample_depth: 2
frame_size: 480

audio_resource: cltl.backend.resource.audio
mic_resource: cltl.backend.resource.microphone

[cltl.video]
resolution: VGA
camera_index: 0

[cltl.backend]
### To run locally with system
run_server: True
server_image_url: http://0.0.0.0:8000/host
server_audio_url: http://0.0.0.0:8000/host
### To run on pepper
# run_server: False
# server_image_url: http://192.168.1.176:8000
# server_audio_url: http://192.168.1.176:8000
storage_url: http://0.0.0.0:8000/storage/
audio_storage_path: ./storage/audio
audio_source_buffer: 16
image_storage_path: ./storage/image
image_cache: 32
scenario_topic: cltl.topic.scenario

[cltl.backend.mic]
topic: cltl.topic.microphone

[cltl.backend.image]
topic: cltl.topic.image
rate: 0.2

[cltl.backend.tts]
topic: cltl.topic.text_out

[cltl.backend.text_output]
## Local console output
remote_url:
## Run on pepper
# remote_url: http://192.168.1.176:8000

[cltl.vad]
implementation: webrtc
mic_topic: cltl.topic.microphone
vad_topic: cltl.topic.vad

[cltl.vad.webrtc]
activity_window: 300
activity_threshold: 0.8
allow_gap: 300
padding: 600

[cltl.asr]
implementation: whisper
sampling_rate: 16000
vad_topic: cltl.topic.vad
asr_topic: cltl.topic.text_in

[cltl.asr.whisper]
model: base
language: en

[cltl.object_recognition]
implementation: proxy

[cltl.object_recognition.proxy]
start_infra: True

[cltl.object_recognition.events]
image_topic: cltl.topic.image
object_topic: cltl.topic.object_recognition

[cltl.chat-ui]
name: chat-ui
agent_id: leolani
external_input: True
timeout: 0

[cltl.chat-ui.events]
local: True
topic_utterance: cltl.topic.text_in
topic_response: cltl.topic.text_out
topic_scenario : cltl.topic.scenario
topic_desire : cltl.topic.desire

[cltl.eliza]
topic_input : cltl.topic.text_in
topic_output : cltl.topic.text_out
intentions: eliza
topic_intention: cltl.topic.intention
topic_desire: cltl.topic.desire

[cltl.leolani.friends]
implementation: memory

[cltl.leolani.keyword]
topic_intention: cltl.topic.intention
topic_desire: cltl.topic.desire
topic_text_in : cltl.topic.text_in
topic_text_out : cltl.topic.text_out

[cltl.context]
topic_scenario: cltl.topic.scenario
topic_speaker: cltl.topic.speaker
topic_intention: cltl.topic.intention
topic_desire: cltl.topic.desire
topic_knowledge: cltl.topic.knowledge
topic_object: cltl.topic.object_recognition
topic_vector_id: cltl.topic.face_id

[cltl.monitoring]
topic_object: cltl.topic.object_recognition
topic_vector_id: cltl.topic.face_id
topic_image: cltl.topic.image
topic_text_in: cltl.topic.text_in
topic_text_out : cltl.topic.text_out

[cltl.bdi]
model = {"init": {"initialized": ["eliza"]}, "eliza": {"quit": ["init"]}}
topic_scenario: cltl.topic.scenario
topic_intention: cltl.topic.intention
topic_desire: cltl.topic.desire

[cltl.leolani]
event_log : ./storage/event_log
brain_log : ./storage/brain
topic_scenario : cltl.topic.scenario
topic_input : cltl.topic.text_in
topic_output : cltl.topic.text_out_leolani

[cltl.leolani.intentions.init]
topic_intention: cltl.topic.intention
topic_desire: cltl.topic.desire
topic_text_in: cltl.topic.text_in
topic_text_out: cltl.topic.text_out
topic_face: cltl.topic.face_recognition
greeting: Do you want to talk to me?

[cltl.leolani.intentions.chat]
intentions : chat, g2kmore
topic_intention: cltl.topic.intention
topic_scenario : cltl.topic.scenario
topic_utterance: cltl.topic.text_in
topic_speaker_mention: cltl.topic.triple_extraction

[cltl.event.kombu]
server: amqp://localhost:5672
exchange: cltl.combot
type: direct
compression: bzip2

[cltl.event_log]
log_dir: ./storage/event_log

[cltl.emissor-data]
path: ./storage/emissor

[cltl.emissor-data.event]
topics: cltl.topic.scenario,
        cltl.topic.image, cltl.topic.microphone,
        cltl.topic.text_in, cltl.topic.text_out, cltl.topic.object_recognition,
        cltl.topic.vad

[environment]
GOOGLE_APPLICATION_CREDENTIALS: config/google_cloud_key.json
